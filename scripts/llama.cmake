set (LLAMACPP_SUPPORT_DEFAULT ON)
if (UNIX)
 set (llama_DIR /mnt/win_e/lib/llama.cpp/build/gcc)
 set (CMAKE_MODULE_PATH "${CMAKE_MODULE_PATH};/usr/share/rocm/cmake;/usr/share/rocmcmakebuildtools/cmake;/usr/lib64/cmake/hip")
# set (USE_ROCM ON)
# set (HIP_SUPPORTED_ARCHS "gfx900")
 set (ROCM_PATH /usr/lib64/rocm)
 find_package (llama)
 if (llama_FOUND)
# pkg_check_modules (PKG_LLAMACPP llama)
# if (PKG_LLAMACPP_FOUND)
  set (LLAMACPP_FOUND TRUE)
#set (LLAMACPP_INCLUDE_DIRS "${PKG_LIBTORCH_INCLUDE_DIRS}")
#set (LLAMACPP_LIBRARIES "${PKG_LIBTORCH_LIBRARIES}")
  set (LLAMACPP_INCLUDE_DIRS "${GGML_INCLUDE_DIR};${LLAMA_INCLUDE_DIR}")
  set (LLAMACPP_LIBRARIES "${GGML_LIBRARY};${llama_LIBRARY}")
 else ()
  if (EXISTS $ENV{LLAMA_ROOT})
   set (LLAMA_ROOT $ENV{LLAMA_ROOT})
  else ()
   set (LLAMA_ROOT $ENV{LIB_ROOT}/llama.cpp)
   #set (LLAMA_ROOT /usr/local/src/llama.cpp)
  endif (EXISTS $ENV{LLAMA_ROOT})
  find_library (LLAMA_LIBRARY llama.so
                PATHS ${LLAMA_ROOT}
                PATH_SUFFIXES src
                DOC "searching for llama.so"
                NO_DEFAULT_PATH)
  if (NOT LLAMA_LIBRARY)
   message (WARNING "could not find llama.so, continuing")
  else ()
   message (STATUS "Found llama.so library \"${LLAMA_LIBRARY}\"")
  endif (NOT LLAMA_LIBRARY)
  if (LLAMA_LIBRARY)
   set (LLAMACPP_FOUND TRUE)
   set (LLAMACPP_LIBRARIES "${LLAMA_LIBRARY}")
   set (LLAMACPP_INCLUDE_DIRS "${LLAMA_ROOT}/include")
  endif (LLAMA_LIBRARY)
 endif (llama_FOUND)
# endif (PKG_LLAMACPP_FOUND)
elseif (WIN32)
 if (VCPKG_USE)
  find_package (llama CONFIG)
  if (LLAMA_FOUND)
   set (LLAMACPP_FOUND TRUE)
   set (LLAMACPP_INCLUDE_DIRS ${VCPKG_INCLUDE_DIR})
   set (LLAMACPP_LIBRARIES ${VCPKG_LIB_DIR}/torch_cpu.lib)
   set (LLAMACPP_LIB_DIR "${VCPKG_BIN_DIR}")
  endif (LLAMA_FOUND)
 endif (VCPKG_USE)
 if (NOT LLAMACPP_FOUND)
  if (EXISTS $ENV{LLAMA_ROOT})
   set (LLAMA_ROOT $ENV{LLAMA_ROOT})
  else ()
   set (LLAMA_ROOT $ENV{LIB_ROOT}/llama.cpp)
  endif (EXISTS $ENV{LLAMA_ROOT})
  find_library (LLAMA_LIBRARY llama.lib
                PATHS ${LLAMA_ROOT}/build/ninja
                PATH_SUFFIXES src
                DOC "searching for llama.lib"
                NO_DEFAULT_PATH)
  if (NOT LLAMA_LIBRARY)
   message (WARNING "could not find llama.lib, continuing")
  else ()
   message (STATUS "Found llama.lib library \"${LLAMA_LIBRARY}\"")
  endif (NOT LLAMA_LIBRARY)
  find_library (GGML_LIBRARY ggml.lib
                PATHS ${LLAMA_ROOT}/build/ninja/ggml
                PATH_SUFFIXES src
                DOC "searching for ggml.lib"
                NO_DEFAULT_PATH)
  if (NOT GGML_LIBRARY)
   message (WARNING "could not find ggml.lib, continuing")
  else ()
   message (STATUS "Found ggml.lib library \"${GGML_LIBRARY}\"")
  endif (NOT GGML_LIBRARY)
  if (LLAMA_LIBRARY AND GGML_LIBRARY)
   set (LLAMACPP_FOUND TRUE)
   set (LLAMACPP_LIBRARIES "${LLAMA_LIBRARY};${GGML_LIBRARY}")
   set (LLAMACPP_INCLUDE_DIRS "${LLAMA_ROOT}/include;${LLAMA_ROOT}/ggml/include")
   set (LLAMACPP_LIB_DIR "${LLAMA_ROOT}/build/ninja/bin")
  endif (LLAMA_LIBRARY AND GGML_LIBRARY)
 endif (NOT LLAMACPP_FOUND)
endif ()
if (LLAMACPP_FOUND)
 option (LLAMACPP_SUPPORT "enable llama.cpp support" ${LLAMACPP_SUPPORT_DEFAULT})
 if (LLAMACPP_SUPPORT)
  add_definitions (-DLLAMACPP_SUPPORT)
 endif (LLAMACPP_SUPPORT)
endif (LLAMACPP_FOUND)
